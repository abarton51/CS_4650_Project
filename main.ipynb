{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba vs. Transformer-based RALMs\n",
    "\n",
    "The purpose of this project is to compare the performance of Retrieval Augmented Language Models (RALMs) based on the newly released Mamba architecture to those based on the more prevalent Transformer architecture. We will compare the [Mamba-Chat](https://huggingface.co/havenhq/mamba-chat) model to the [Dolly](https://huggingface.co/databricks/dolly-v2-3b) model. Both these models are approximately 2.8B parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports, Environment Setup, and Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to facilitate the use of this notebook in colab, load the rest of the repo. ONLY RUN THIS CODE IN COLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
    "import colab_github\n",
    "colab_github.github_auth(persistent_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after updating ssh key on github account if necessary, run below\n",
    "!git clone git@github.com:abarton51/CS_4650_Project.git\n",
    "!mv CS_4650_Project/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install causal-conv1d>=1.2.0\n",
    "!pip install mamba-ssm\n",
    "!pip install langchain\n",
    "!pip install sentence-transformers\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For COLAB, if you have not done so before, unzip the tarball file in google drive to get all the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf drive/MyDrive/Mamba_RAG/CS_4650_Project/data/triviaqa-rc.tar.gz drive/MyDrive/Mamba_RAG/CS_4650_Project/data/triviaqa-rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "#from mamba_ralm import MambaRALM\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "import vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Construct Vector Database\n",
    "\n",
    "Now let us construct a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path = \"data/triviaqa-rc/evidence/web/0\"\n",
    "triviaqa_vector_store = vector_store.RAGVectorStore(data_directory_path, HuggingFaceBgeEmbeddings(), \"FAISS\")\n",
    "\n",
    "print(\"staring db creation\")\n",
    "\n",
    "db = triviaqa_vector_store.get_db(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the capital of Japan?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "\"\"\"Example Output: Japan[a] is an island country in East Asia. It is in the northwest Pacific Ocean and is bordered on the west by the Sea of Japan, extending from the \n",
    "Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south. Japan is a part of the Ring of Fire, and spans an \n",
    "archipelago of 14,125 islands, with the five main islands being Hokkaido, Honshu (the \"mainland\"), Shikoku, Kyushu, and Okinawa. Tokyo is the country's \n",
    "capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Select the desired model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaRALM(\"havenhq/mamba-chat\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.provide_no_context = True # for testing\n",
    "model._no_context_string = \"The station went on the air as KXIV in 1989. It functioned as the second independent station for the Salt Lake City area. In 1993, Larry H. Miller, the then-owner of the Utah Jazz of the NBA, purchased the station and renamed it KJZZ-TV; it also became the new TV home of the basketball team for 16 seasons. During Miller's ownership, the station affiliated for five years with UPN, with the station's decision not to renew leading to accusations of racism against management; in the latter years, operations and programming were outsourced in turn to two other Salt Lake stations.\"\n",
    "output = model.predict(\"What team does KJZZ-TV broadcast for?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Perform Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the evaluation dataset, which we will use to evaluate our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_name = \"wikipedia-dev\"\n",
    "evaluation_ds_filepath = \"data/triviaqa-rc/qa/{ds_name}.json\".format(ds_name=evaluation_dataset_name)\n",
    "\n",
    "with open (evaluation_ds_filepath, \"r\") as json_file:\n",
    "\n",
    "    eval_ds = json.load(json_file)[\"Data\"]\n",
    "\n",
    "model.provide_no_context = False\n",
    "model._no_context_string = \"\" # Doesn't matter since provide_no_context is False\n",
    "\n",
    "MAX_EVALS = 100\n",
    "\n",
    "evals = 0\n",
    "accurate_evals = 0\n",
    "\n",
    "#evaluation loop\n",
    "for i in range(min(len(eval_ds), MAX_EVALS)):\n",
    "\n",
    "    correct_answers = [answer.lower() for answer in eval_ds[i][\"Answer\"][\"Aliases\"]]\n",
    "\n",
    "    model_answer = model.predict(eval_ds[i][\"Question\"]).lower()\n",
    "\n",
    "    if model_answer in correct_answers:\n",
    "\n",
    "        accurate_evals += 1\n",
    "\n",
    "    evals += 1\n",
    "\n",
    "print(\"Evaluation Complete\")\n",
    "print(\"Over {evals} datapoints, the model accurately answered {accurate_evals}, reflecting an over all accuracy of {overall_accuracy}\".format(\n",
    "    evals=evals,\n",
    "    accurate_evals=accurate_evals,\n",
    "    overall_accuracy=(accurate_evals/evals)\n",
    "))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4650_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
