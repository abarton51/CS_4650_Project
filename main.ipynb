{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba vs. Transformer-based RALMs\n",
    "\n",
    "The purpose of this project is to compare the performance of Retrieval Augmented Language Models (RALMs) based on the newly released Mamba architecture to those based on the more prevalent Transformer architecture. We will compare the [Mamba-Chat](https://huggingface.co/havenhq/mamba-chat) model to the [Dolly](https://huggingface.co/databricks/dolly-v2-3b) model. Both these models are approximately 2.8B parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports, Environment Setup, and Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to facilitate the use of this notebook in colab, load the rest of the repo. ONLY RUN THIS CODE IN COLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
    "import colab_github\n",
    "colab_github.github_auth(persistent_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after updating ssh key on github account if necessary, run below\n",
    "!git clone git@github.com:abarton51/CS_4650_Project.git\n",
    "!mv CS_4650_Project/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For COLAB, if you have not done so before, unzip the tarball file in google drive to get all the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf drive/MyDrive/Mamba_RAG/CS_4650_Project/data/triviaqa-rc.tar.gz -C data/triviaqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from datasets import load_dataset\n",
    "#from mamba_ralm import MambaRALM\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "import vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Construct Vector Database\n",
    "\n",
    "Now let us construct a Vector Database, or load it if already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path = \"data/triviaqa/evidence\"\n",
    "\n",
    "triviaqa_vector_store = vector_store.RAGVectorStore(data_directory_path)\n",
    "\n",
    "try:\n",
    "\n",
    "    db = triviaqa_vector_store.load_db(\"triviaqa_vector_store\")\n",
    "\n",
    "except RuntimeError:\n",
    "\n",
    "    #db doesnt exist (i hope that some other random error wasnt caught)\n",
    "\n",
    "    db = triviaqa_vector_store.create_db(\"triviaqa_vector_store\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of Japan?\"\n",
    "docs = db.similarity_search(query, k=4)\n",
    "print([docs])\n",
    "\"\"\"Example Output: Japan[a] is an island country in East Asia. It is in the northwest Pacific Ocean and is bordered on the west by the Sea of Japan, extending from the \n",
    "Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south. Japan is a part of the Ring of Fire, and spans an \n",
    "archipelago of 14,125 islands, with the five main islands being Hokkaido, Honshu (the \"mainland\"), Shikoku, Kyushu, and Okinawa. Tokyo is the country's \n",
    "capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Select the desired model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaRALM(\"havenhq/mamba-chat\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.provide_no_context = True # for testing\n",
    "model._no_context_string = \"The station went on the air as KXIV in 1989. It functioned as the second independent station for the Salt Lake City area. In 1993, Larry H. Miller, the then-owner of the Utah Jazz of the NBA, purchased the station and renamed it KJZZ-TV; it also became the new TV home of the basketball team for 16 seasons. During Miller's ownership, the station affiliated for five years with UPN, with the station's decision not to renew leading to accusations of racism against management; in the latter years, operations and programming were outsourced in turn to two other Salt Lake stations.\"\n",
    "output = model.predict(\"What team does KJZZ-TV broadcast for?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Perform Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the evaluation dataset, which we will use to evaluate our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "evaluation_dataset_name = \"wikipedia-dev\"\n",
    "evaluation_ds_filepath = \"data/triviaqa-rc/qa/{ds_name}.json\".format(ds_name=evaluation_dataset_name)\n",
    "\n",
    "with open (evaluation_ds_filepath, \"r\") as json_file:\n",
    "\n",
    "    eval_ds = json.load(json_file)[\"Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(ord(\"\\\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'data/triviaqa-rc/evidence/wikipedia/John_\"Hannibal\"_Smith.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m filepaths:\n\u001b[0;32m     26\u001b[0m     filename \u001b[38;5;241m=\u001b[39m replace_invalid_characters(filepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jasko\\anaconda3\\envs\\4650_proj3\\Lib\\shutil.py:419\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    418\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 419\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\jasko\\anaconda3\\envs\\4650_proj3\\Lib\\shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    254\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    259\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'data/triviaqa-rc/evidence/wikipedia/John_\"Hannibal\"_Smith.txt'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def get_filepath(entry : dict):\n",
    "    return [page['Filename'] for page in entry[\"EntityPages\"]]\n",
    "\n",
    "invalid_chars = {\n",
    "    \":\": \"_\",\n",
    "    \"\\\"\": \"_\",\n",
    "    \"*\": \"_\",\n",
    "    \"?\": \"_\",\n",
    "}\n",
    "\n",
    "def replace_invalid_characters(filename : str):\n",
    "\n",
    "    translated_filename = filename.translate(invalid_chars).replace(\"\\\"\", \"_\")\n",
    "\n",
    "    return translated_filename\n",
    "\n",
    "new_folder = 'data/triviaqa-rc/wikipedia_relevant_evidence/'\n",
    "existing_folder = \"data/triviaqa-rc/evidence/wikipedia/\"\n",
    "\n",
    "for qa in eval_ds:\n",
    "    filepaths = get_filepath(qa)\n",
    "    for filepath in filepaths:\n",
    "        filename = replace_invalid_characters(filepath.split(\"\\\\\")[-1].split(\"/\")[-1])\n",
    "        shutil.copy(os.path.join(existing_folder, filepath), new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7993\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_name = \"wikipedia-dev\"\n",
    "evaluation_ds_filepath = \"data/triviaqa-rc/qa/{ds_name}.json\".format(ds_name=evaluation_dataset_name)\n",
    "\n",
    "with open (evaluation_ds_filepath, \"r\") as json_file:\n",
    "\n",
    "    eval_ds = json.load(json_file)[\"Data\"]\n",
    "\n",
    "model.provide_no_context = False\n",
    "model._no_context_string = \"\" # Doesn't matter since provide_no_context is False\n",
    "\n",
    "MAX_EVALS = 100\n",
    "\n",
    "evals = 0\n",
    "accurate_evals = 0\n",
    "\n",
    "#evaluation loop\n",
    "for i in range(min(len(eval_ds), MAX_EVALS)):\n",
    "\n",
    "    correct_answers = [answer.lower() for answer in eval_ds[i][\"Answer\"][\"Aliases\"]]\n",
    "\n",
    "    model_answer = model.predict(eval_ds[i][\"Question\"]).lower()\n",
    "\n",
    "    if model_answer in correct_answers:\n",
    "\n",
    "        accurate_evals += 1\n",
    "\n",
    "    evals += 1\n",
    "\n",
    "print(\"Evaluation Complete\")\n",
    "print(\"Over {evals} datapoints, the model accurately answered {accurate_evals}, reflecting an over all accuracy of {overall_accuracy}\".format(\n",
    "    evals=evals,\n",
    "    accurate_evals=accurate_evals,\n",
    "    overall_accuracy=(accurate_evals/evals)\n",
    "))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4650_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
