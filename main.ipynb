{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba vs. Transformer-based RALMs\n",
    "\n",
    "The purpose of this project is to compare the performance of Retrieval Augmented Language Models (RALMs) based on the newly released Mamba architecture to those based on the more prevalent Transformer architecture. We will compare the [Mamba-Chat](https://huggingface.co/havenhq/mamba-chat) model to the [Dolly](https://huggingface.co/databricks/dolly-v2-3b) model. Both these models are approximately 2.8B parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to facilitate the use of this notebook in colab, load the rest of the repo. ONLY RUN THIS CODE IN COLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
    "import colab_github\n",
    "colab_github.github_auth(persistent_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after updating ssh key on github account if necessary, run below\n",
    "!git clone git@github.com:abarton51/CS_4650_Project.git\n",
    "!mv CS_4650_Project/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install causal-conv1d>=1.2.0\n",
    "!pip install mamba-ssm\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from mamba_ralm import MambaRALM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Construct Vector Database\n",
    "\n",
    "Now let us construct a Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "import vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path = \"/content/drive/MyDrive/Mamba_RAG/CS_4650_Project/data/triviaqa-rc/evidence\"\n",
    "vector_store = vector_store.RAGVectorStore(data_directory_path, HuggingFaceBgeEmbeddings(), \"FAISS\")\n",
    "vector_store.create_loader()\n",
    "vector_store.load_docs()\n",
    "vector_store.create_text_splitter(chunk_size=1000, chunk_overlap=0)\n",
    "vector_store.split_text()\n",
    "db = vector_store.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the capital of Japan?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "\"\"\"Example Output: Japan[a] is an island country in East Asia. It is in the northwest Pacific Ocean and is bordered on the west by the Sea of Japan, extending from the \n",
    "Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south. Japan is a part of the Ring of Fire, and spans an \n",
    "archipelago of 14,125 islands, with the five main islands being Hokkaido, Honshu (the \"mainland\"), Shikoku, Kyushu, and Okinawa. Tokyo is the country's \n",
    "capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Select the desired model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaRALM()\n",
    "model.predict(\"What is the capital of Japan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Perform Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the evaluation dataset, which we will use to evaluate our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_name = \"wikipedia-dev\"\n",
    "evaluation_ds_filepath = \"data/triviaqa-rc/qa/{ds_name}.json\".format(ds_name=evaluation_dataset_name)\n",
    "\n",
    "with open (evaluation_ds_filepath, \"r\") as json_file:\n",
    "\n",
    "    eval_ds = json.load(json_file)[\"Data\"]\n",
    "\n",
    "MAX_EVALS = 100\n",
    "\n",
    "evals = 0\n",
    "accurate_evals = 0\n",
    "\n",
    "#evaluation loop\n",
    "for i in range(min(len(eval_ds), MAX_EVALS)):\n",
    "\n",
    "    correct_answers = [answer.lower() for answer in eval_ds[i][\"Answer\"][\"Aliases\"]]\n",
    "\n",
    "    model_answer = model.predict(eval_ds[i][\"Question\"]).lower()\n",
    "\n",
    "    if model_answer in correct_answers:\n",
    "\n",
    "        accurate_evals += 1\n",
    "\n",
    "    evals += 1\n",
    "\n",
    "print(\"Evaluation Complete\")\n",
    "print(\"Over {evals} datapoints, the model accurately answered {accurate_evals}, reflecting an over all accuracy of {overall_accuracy}\".format(\n",
    "    evals=evals,\n",
    "    accurate_evals=accurate_evals,\n",
    "    overall_accuracy=(accurate_evals/evals)\n",
    "))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4650_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
