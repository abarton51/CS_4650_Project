{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba vs. Transformer-based RALMs\n",
    "\n",
    "The purpose of this project is to compare the performance of Retrieval Augmented Language Models (RALMs) based on the newly released Mamba architecture to those based on the more prevalent Transformer architecture. We will compare the [Mamba-Chat](https://huggingface.co/havenhq/mamba-chat) model to the [Dolly](https://huggingface.co/databricks/dolly-v2-3b) model. Both these models are approximately 2.8B parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Dataset\n",
    "\n",
    "Here we load in the relevant benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"natural_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Select the desired model here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4650_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
