{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba vs. Transformer-based RALMs\n",
    "\n",
    "The purpose of this project is to compare the performance of Retrieval Augmented Language Models (RALMs) based on the newly released Mamba architecture to those based on the more prevalent Transformer architecture. We will compare the [Mamba-Chat](https://huggingface.co/havenhq/mamba-chat) model to the [Dolly](https://huggingface.co/databricks/dolly-v2-3b) model. Both these models are approximately 2.8B parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports, Environment Setup, and Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to facilitate the use of this notebook in colab, load the rest of the repo. ONLY RUN THIS CODE IN COLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
    "import colab_github\n",
    "colab_github.github_auth(persistent_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after updating ssh key on github account if necessary, run below\n",
    "!git clone git@github.com:abarton51/CS_4650_Project.git\n",
    "!mv CS_4650_Project/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For COLAB, if you have not done so before, unzip the tarball file in google drive to get all the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf drive/MyDrive/Mamba_RAG/CS_4650_Project/data/triviaqa-rc.tar.gz -C data/triviaqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from datasets import load_dataset\n",
    "from mamba_ralm import MambaRALM\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from triviaqa_evaluation import evaluate_triviaqa\n",
    "from tqdm import tqdm\n",
    "import vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Construct Vector Database\n",
    "\n",
    "Now let us construct a Vector Database, or load it if already created. First let us initialize a Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triviaqa_vector_store = vector_store.RAGVectorStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a vector database, run the following code. Otherwise, run the code further down to load the database from google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = triviaqa_vector_store.create_db(\"triviaqa_vector_store\", \"data/triviaqa/wikipedia_relevant_evidence\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the vector db from google drive, run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 17OSdKZTlyfKxGJ7unZqNth5gmmb8y8Kh\n",
    "!unzip triviaqa_vector_store.zip -d vector_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = triviaqa_vector_store.load_db(\"triviaqa_vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the vector db with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the capital of Japan?\"\n",
    "docs = db.similarity_search(query, k=4)\n",
    "print([docs])\n",
    "\"\"\"Example Output: Japan[a] is an island country in East Asia. It is in the northwest Pacific Ocean and is bordered on the west by the Sea of Japan, extending from the \n",
    "Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south. Japan is a part of the Ring of Fire, and spans an \n",
    "archipelago of 14,125 islands, with the five main islands being Hokkaido, Honshu (the \"mainland\"), Shikoku, Kyushu, and Okinawa. Tokyo is the country's \n",
    "capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model. Select the desired model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaRALM(\"havenhq/mamba-chat\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.provide_no_context = True # for testing\n",
    "model._no_context_string = \"The station went on the air as KXIV in 1989. It functioned as the second independent station for the Salt Lake City area. In 1993, Larry H. Miller, the then-owner of the Utah Jazz of the NBA, purchased the station and renamed it KJZZ-TV; it also became the new TV home of the basketball team for 16 seasons. During Miller's ownership, the station affiliated for five years with UPN, with the station's decision not to renew leading to accusations of racism against management; in the latter years, operations and programming were outsourced in turn to two other Salt Lake stations.\"\n",
    "output = model.predict(\"What team does KJZZ-TV broadcast for?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Generate LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the evaluation dataset, which we will use to evaluate our RAG system. Since we do not have the computational resources to evaluate over the entire TriviaQA dataset, we will evaluate on a randomly sampled subset of the TriviaQA wikipedia-dev dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "evaluation_dataset_name = \"wikipedia-dev\"\n",
    "evaluation_ds_filepath = \"data/triviaqa-rc/qa/{ds_name}.json\".format(ds_name=evaluation_dataset_name)\n",
    "\n",
    "with open (evaluation_ds_filepath, \"r\") as json_file:\n",
    "\n",
    "    eval_ds = json.load(json_file)[\"Data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate the answers from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_responses = {}\n",
    "\n",
    "K_VALUE = 4\n",
    "\n",
    "for question in tqdm(eval_ds):\n",
    "\n",
    "    question_text = question[\"Question\"]\n",
    "\n",
    "    generated_responses[question[\"QuestionId\"]] = model.predict(question_text, k=K_VALUE)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Perform Evaluation\n",
    "\n",
    "Finally, let's compare to ground truth using the official TriviaQA evaluation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output = evaluate_triviaqa(ground_truth={question[\"QuestionId\"]: question[\"Answer\"] for question in eval_ds} ,predicted_answers=generated_responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4650_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
